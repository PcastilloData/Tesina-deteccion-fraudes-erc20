# Tesina - DetecciÃ³n de Fraudes en Tokens ERC-20

VersiÃ³n inicial simplificada del proyecto de tesis que desarrolla una herramienta para detectar patrones de manipulaciÃ³n y posibles estafas en tokens **ERC-20**, combinando anÃ¡lisis **on-chain** y **machine learning** con datos de **BigQuery**.  
Esta versiÃ³n presenta una base funcional y resumida de la herramienta para detecciÃ³n temprana de fraudes cripto.

---

# DetecciÃ³n de Patrones de ManipulaciÃ³n en Mercados CriptogrÃ¡ficos

**Autor:** Pablo Castillo MartÃ­nez  
**Lugar:** Santiago de Chile  
**Fecha:** 18 de septiembre de 2025  
**Proyecto:** Trabajo Final del MÃ¡ster en Data Science y Big Data â€“ Universidad Complutense de Madrid  

---

## ğŸ§  DescripciÃ³n
Esta versiÃ³n inicial del proyecto implementa una herramienta bÃ¡sica de detecciÃ³n de fraudes en tokens **ERC-20**, usando **modelos supervisados** y datos on-chain.  
El enfoque combina **Google BigQuery** para la extracciÃ³n y procesamiento de datos, junto con modelos de aprendizaje automÃ¡tico de complejidad media.

El objetivo principal de esta versiÃ³n es ofrecer una base reproducible y fÃ¡cilmente extensible, priorizando claridad y simplicidad sobre optimizaciÃ³n.

---

## âš™ï¸ Estructura del proyecto

| Archivo / Notebook | DescripciÃ³n |
|--------------------|-------------|
| `tfm_2025_09_basededatos.ipynb` | ExtracciÃ³n y construcciÃ³n de la base de datos desde BigQuery y CoinGecko. |
| `tfm_2025_09_preprocesado.ipynb` | Limpieza, imputaciÃ³n, codificaciÃ³n y escalado de datos. |
| `tfm_2025_09_modelado.ipynb` | Entrenamiento de modelos bÃ¡sicos (Logistic Regression, Random Forest, XGBoost, LightGBM). |
| `tfm_2025_09_gui.py` | Interfaz grÃ¡fica inicial (Tkinter) para pruebas de clasificaciÃ³n. |

---

## ğŸ§© Modelos utilizados
- **RegresiÃ³n LogÃ­stica** (mejor desempeÃ±o global ~75 % balanced accuracy)  
- **Random Forest**  
- **XGBoost / LightGBM**  
- **Gradient Boosting**

> ğŸ’¡ En esta versiÃ³n, los modelos fueron entrenados sobre un subconjunto reducido del dataset original para facilitar la replicaciÃ³n.

---

## ğŸ“Š Dataset
Datos pÃºblicos on-chain desde **BigQuery (GCP)**, procesando informaciÃ³n resumida de ~5 000 tokens ERC-20.  
Variables incluidas:
- NÃºmero de transferencias  
- ConcentraciÃ³n top 10 holders  
- AntigÃ¼edad del token  
- Actividad media y desviaciÃ³n de transferencias  

---

## ğŸš€ Resultados
- **RegresiÃ³n LogÃ­stica** obtuvo el mejor equilibrio entre precisiÃ³n y estabilidad.  
- Modelos complejos mostraron sobreajuste en esta versiÃ³n reducida.  
- Se implementÃ³ una **interfaz grÃ¡fica simple** para realizar inferencias locales.

---

## ğŸ”® PrÃ³ximos pasos
- Integrar fuentes adicionales (Nansen, Dune, Etherscan API).  
- Aumentar el tamaÃ±o y balanceo del dataset.  
- Migrar la herramienta hacia un entorno web interactivo.  

---

## ğŸ“„ Licencia
VersiÃ³n simplificada publicada bajo la **Licencia MIT**, permitiendo uso, modificaciÃ³n y redistribuciÃ³n con atribuciÃ³n al autor original.

---
